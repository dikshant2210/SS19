{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate News Headlines using RNN\n",
    "We will use the kaggle Indian news headline dataset (https://www.kaggle.com/therohk/india-headlines-news-dataset/downloads/india-headlines-news-dataset.zip/5) <br/>\n",
    "A cleaned dataset of 100,000 is produced from this. We want to generate new headlines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes! GPU!\n"
     ]
    }
   ],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "if use_cuda:\n",
    "    print('Yes! GPU!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    }
   ],
   "source": [
    "with open('data/news-headlines-trimmed.txt') as f:\n",
    "    data = f.read()\n",
    "\n",
    "data = data.split('\\n')[:10000] # fast training\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start of Sentence (SOS) is added to the begining of every headline. <br/>\n",
    "End of Sentence (EOS) is to indicate when to stop generating characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS = 0\n",
    "EOS = 127"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode sentence as sequence of one-hot vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encoding\n",
    "def one_hotter(c):\n",
    "    vec = torch.zeros(128)\n",
    "    vec[ord(c)] = 1.0\n",
    "    return vec\n",
    "\n",
    "def encode_sentence(s):\n",
    "    v = torch.zeros(1, len(s)+1, 128)\n",
    "    \n",
    "    # append SOS\n",
    "    vec = torch.zeros(128)\n",
    "    vec[SOS] = 1.0\n",
    "    v[0, 0, :] = vec\n",
    "    \n",
    "    for i in range(len(s)):\n",
    "        v[0, i+1, :] = one_hotter(s[i])\n",
    "        \n",
    "    # append EOS\n",
    "    # vec = torch.zeros(128)\n",
    "    # vec[EOS] = 1.0\n",
    "    # v[0, len(s)+1, :] = vec\n",
    "    \n",
    "    return v.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = encode_sentence('ab')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RnnNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        \n",
    "        super(RnnNet, self).__init__()\n",
    "        self.input_dim = 128 # one-hot encoding of ascii \n",
    "        # self.seq_len = 28\n",
    "        self.hidden_dim = 100\n",
    "        self.batch_size = 1 # sorry! variable length sentences. \n",
    "        # We can pad and make batches though. But let's stick to simplicity\n",
    "        self.num_class = self.input_dim\n",
    "        \n",
    "        self.rnn = nn.GRU(self.input_dim, self.hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(self.hidden_dim, self.num_class)\n",
    "\n",
    "    def forward(self, x, h0):\n",
    "        \n",
    "        # h0 = torch.randn(1, self.batch_size, self.hidden_dim).to(device)\n",
    "        # run the LSTM along the sequences of length seq_len\n",
    "        \n",
    "        x, h = self.rnn(x, h0)      # dim: batch_size x seq_len x hidden_dim\n",
    "        \n",
    "        # make the Variable contiguous in memory (a PyTorch artefact)\n",
    "        x = x.contiguous()\n",
    "\n",
    "        # reshape the Variable so that each row contains one token\n",
    "        x = x.view(-1, x.shape[2])       # dim: batch_size*seq_len x hidden_dim (note batch_size=1)\n",
    "\n",
    "        # apply the fully connected layer and obtain the output (before softmax) for each token\n",
    "        x = self.fc(x)                   # dim: batch_size*seq_len x num_class\n",
    "\n",
    "        # apply log softmax on each token's output (this is recommended over applying softmax\n",
    "        # since it is numerically more stable)\n",
    "        return F.log_softmax(x, dim=1), h   # dim: batch_size*seq_len x num_class & dim(h): 1 x 1(batch) x hidden_dim\n",
    "    \n",
    "    def genh(self):\n",
    "        return torch.randn(1, self.batch_size, self.hidden_dim).to(device) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RnnNet().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import trange\n",
    "import logging\n",
    "\n",
    "# logging.basicConfig(format='%(asctime)s [%(levelname)-8s] %(message)s')\n",
    "# logger = logging.getLogger()\n",
    "# logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Heading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_headlines(num=5):\n",
    "    model.eval()\n",
    "    \n",
    "    for i in range(num):\n",
    "        gen= ''\n",
    "        h = model.genh()\n",
    "        i = 0\n",
    "        prev = torch.zeros(1, 1, 128).to(device)\n",
    "        prev[0,0,0] = 1.0\n",
    "        \n",
    "        while(True):\n",
    "            output, h = model(prev, h)\n",
    "            s = torch.argmax(output, dim=1)\n",
    "\n",
    "            # Stop if EOS is generated\n",
    "            if s == 127:\n",
    "                break\n",
    "\n",
    "            # update generated sentence\n",
    "            gen += chr(s)    \n",
    "            prev = torch.zeros(1, 1, 128).to(device)\n",
    "            prev[0,0,s] = 1.0\n",
    "\n",
    "            i += 1\n",
    "            if i > 200:\n",
    "                break\n",
    "\n",
    "        print(gen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 35/10000 [00:00<00:29, 343.38it/s, loss=4.862]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:27<00:00, 368.94it/s, loss=1.922]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "proment on to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to b\n",
      "for to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10000 [00:00<?, ?it/s, loss=2.399]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the karnation of stang to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to b\n",
      "restor stanes of stanes for mandara\n",
      "congres of proment of stang to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be to be\n",
      "\n",
      "epoch 2/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:26<00:00, 370.94it/s, loss=1.732]\n",
      "  0%|          | 34/10000 [00:00<00:29, 332.63it/s, loss=2.375]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "project on the to be restrite to be restrite\n",
      "state congress of the to be restrite\n",
      "state congress of the to be restrite\n",
      "firm to be restrite to be restrite to be restrite\n",
      "and a state congress of the to be restrite\n",
      "\n",
      "epoch 3/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:26<00:00, 373.09it/s, loss=1.646]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phoolan death to be restrate congress and and and\n",
      "congress and to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to\n",
      "state of a state of and and dead\n",
      "accised in the to be restrate congress\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 34/10000 [00:00<00:29, 335.12it/s, loss=2.367]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to \n",
      "\n",
      "epoch 4/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:26<00:00, 370.43it/s, loss=1.639]\n",
      "  0%|          | 0/10000 [00:00<?, ?it/s, loss=2.314]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "probe in the to be remand of and and and\n",
      "project of a state of and and and\n",
      "tring state of and and and and and\n",
      "congress a state of and and and and and\n",
      "karnataka an to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to to\n",
      "\n",
      "epoch 5/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:26<00:00, 373.24it/s, loss=1.623]\n",
      "  0%|          | 0/10000 [00:00<?, ?it/s, loss=2.312]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accise to to to the to the to be restrits state\n",
      "police for death to be restrits state of and\n",
      "the protest and to to the to be restrits state\n",
      "phoolan dead to to the to be restrits state of and\n",
      "arrested for death to be restrits state\n",
      "\n",
      "epoch 6/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:26<00:00, 371.05it/s, loss=1.591]\n",
      "  0%|          | 0/10000 [00:00<?, ?it/s, loss=2.309]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phoolan dead to be review states of phoolan\n",
      "help to the to the to the to the to the to the to be restrict\n",
      "phoolan dead to be review states of phoolan\n",
      "rajkaran karnataka and to the to the to the to the to be restrict\n",
      "police to to the to the to the to the to the to the to be restrict\n",
      "\n",
      "epoch 7/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:26<00:00, 371.47it/s, loss=1.624]\n",
      "  0%|          | 0/10000 [00:00<?, ?it/s, loss=2.323]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state of and to to the to the to the to the promise\n",
      "phoolan dead on the to the to the to the promise\n",
      "the resident to the to the to the to the promise\n",
      "congress and to to the to the to the to the to the promise\n",
      "no to to the to the to the to the to the promise\n",
      "\n",
      "epoch 8/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:26<00:00, 377.32it/s, loss=1.482]\n",
      "  0%|          | 37/10000 [00:00<00:27, 364.30it/s, loss=2.361]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "police to the to the to the protest of phoolan\n",
      "and the protest of the protest\n",
      "and the protest of the protest\n",
      "10 cong seeks and to to the protest of phoolan\n",
      "units and the protest of the protest\n",
      "\n",
      "epoch 9/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:25<00:00, 387.26it/s, loss=1.488]\n",
      "  0%|          | 37/10000 [00:00<00:27, 366.37it/s, loss=2.315]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state of the to the to the congress\n",
      "manipur manipur states to be to the congress\n",
      "sc of the protest and the protest\n",
      "congress and the protest and the protest\n",
      "manipur states to be to the to the congress\n",
      "\n",
      "epoch 10/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:25<00:00, 387.13it/s, loss=1.473]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "manipur in the to the cong response\n",
      "phoolan manipur states to be to the congress\n",
      "to to tech of the protest\n",
      "congress and the protest and the congress\n",
      "phoolan manipur states to be to the congress\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    \n",
    "    # Use tqdm for progress bar\n",
    "    t = trange(len(data)) \n",
    "    print('\\nepoch {}/{}'.format(epoch+1, epochs))\n",
    "    for i in t:\n",
    "        # Get the representation of sentence\n",
    "        d = data[i]\n",
    "        d = d.strip()\n",
    "        if len(d) == 0: # empty sentences are not allowed\n",
    "            break\n",
    "\n",
    "        enc_sen = encode_sentence(d)\n",
    "        h0 = model.genh()\n",
    "        output, _ = model(enc_sen, h0) # dim: seq_len x num_class\n",
    "        target = [ord(c) for c in d] + [EOS]\n",
    "        target = torch.LongTensor(target).to(device)\n",
    "\n",
    "        # zero param grads\n",
    "        optimizer.zero_grad()\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if i%100 == 0:\n",
    "            t.set_postfix(loss='{:05.3f}'.format(loss.item()))\n",
    "    \n",
    "    # print samples from the language model\n",
    "    gen_headlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Todo\n",
    "1. sample instead of argmax for next character (for more diversity in sentence generation)\n",
    "2. Use multiple layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_headlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
