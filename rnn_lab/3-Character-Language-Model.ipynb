{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Language Models, etc.\n",
    "\n",
    "### We pose our problem as sequence prediction. \n",
    "\n",
    "### Given a sequence on say n-characters, we have to predict what will show up next. \n",
    "\n",
    "### Let's think of why this works?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Can humans do thi_?\n",
    "\n",
    "* thereb_\n",
    "* Luke, I __ your father."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "* There are patterns in character sequences that form valid comprehensible text. For example, `qqrxt` is not a word - you may assert.\n",
    "\n",
    "**Turns out, the network we'll be training will capture just this!**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Our usual imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch import optim, nn\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Vocabulary\n",
    "\n",
    "We assume a finite vocabulary. \n",
    "\n",
    "The vocabulary could be words, or characters or whatever unit which suits your task. \n",
    "\n",
    "Given vocabulary is finite, we can pose this as a classification problem.\n",
    "\n",
    "\n",
    "Sure, we can't put text/characters through neural networks, we put an integers which correspond to the text/characters. A bijective map between the two, we maintain using `Indexing`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "class Indexing:\n",
    "    def __init__(self, vocabulary):\n",
    "        self.v2idx = {}\n",
    "        self.idx2v = {}\n",
    "        self.counter = 0\n",
    "        for v in vocabulary:\n",
    "            self.add(v)\n",
    "        \n",
    "    def add(self, v):\n",
    "        assert(v not in self.v2idx)\n",
    "        self.v2idx[v] = self.counter\n",
    "        self.idx2v[self.counter] = v\n",
    "        self.counter += 1\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.v2idx)\n",
    "        \n",
    "    def direct(self, v):\n",
    "        return self.v2idx[v]\n",
    "    \n",
    "    def inverse(self, idx):\n",
    "        return self.idx2v[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## tl;dr\n",
    "\n",
    "```python\n",
    "vocabulary = ['sea', 'salt', 'is', 'a', 'great', 'seasoning']\n",
    "mapping = Indexing(vocabulary)\n",
    "\n",
    "mapping.direct('sea') # => 0\n",
    "mapping.inverse(0) # => sea\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Embedding \n",
    "\n",
    "* Regression => [4, 2, 1, 5] => Too dense. \n",
    "* Let's model vocabulary as classes. We'll use something called one-hot embedding.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Image Courtesy: https://www.datascience.com/\n",
    "![One hot embedding](static/nn_embed.png)\n",
    "\n",
    "We'll be doing the same thing, except for **characters instead of words**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## one-hot embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "class OneHotEmbedding(nn.Module):\n",
    "    def __init__(self, size):\n",
    "        super().__init__()\n",
    "        self.size = size\n",
    "        \n",
    "    def encoding(self, idx):\n",
    "        x = torch.zeros(self.size).float()\n",
    "        # key part\n",
    "        x[idx] = 1.0\n",
    "        return x\n",
    "       \n",
    "    def forward(self, x):\n",
    "        # x  we get is going to be a T x B sequence.\n",
    "        T, B = x.size()\n",
    "        \n",
    "        # We'll provide a T x B x H (self.size) sequence\n",
    "        H = self.size\n",
    "        target = torch.zeros(T, B, H)\n",
    "        for b in range(B):\n",
    "            for t in range(T):\n",
    "                key = x[t, b].item()\n",
    "                target[t, b, :] = self.encoding(key)\n",
    "        return target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Let's build and test RNNs!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "class SequenceLearner(nn.Module):\n",
    "    def __init__(self, embedding, input_size, hidden_size, n_layers, output_size):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = embedding\n",
    "        self.n_layers = n_layers\n",
    "        self.output_size = output_size\n",
    "        self.rnn = nn.RNN(input_size, hidden_size, n_layers)\n",
    "        self.linear = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def h0(self, batch_size):\n",
    "        return torch.zeros(self.n_layers, batch_size, self.hidden_size)\n",
    "        \n",
    "    def forward(self, xt, ht):\n",
    "        xt_embedded = self.embedding(xt)\n",
    "        xt_plus1, ht_plus1 = self.rnn(xt_embedded, ht)\n",
    "        xt_plus1 = self.linear(xt_plus1)\n",
    "        return xt_plus1, ht_plus1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "An RNN, and linear layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Some Tricks\n",
    "\n",
    "It helps to have a small dataset with guaranteed convergence while developing your models. \n",
    "\n",
    "### Why?\n",
    "\n",
    "* Prototyping gets faster.\n",
    "    * Less computationally intensive.\n",
    "    * Faster debug cycles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Turtle Logo\n",
    "\n",
    "I propose turtle logo!\n",
    "\n",
    "![Turtle Logo Syntax](static/logo.png)\n",
    "\n",
    "We'll work with a smaller subset and with a bit of variations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Our objective\n",
    "\n",
    "Our network should learn to hallucinate a valid turtle logo program, which looks something like below.\n",
    "\n",
    "```logo\n",
    "forward 50\n",
    "right 90\n",
    "forward 50\n",
    "backward 50\n",
    "right 90\n",
    "```\n",
    "\n",
    "We'll constrain the rotate arguments `left`, `right` to have only `90` as argument, while others can have any number less than 360. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "class SimpleTurtleLogoDataset(Dataset):\n",
    "    def __init__(self, length):\n",
    "        self.size = length\n",
    "        self.cmds = [\"forward\", \"backward\", \"right\", \"left\"]\n",
    "        \n",
    "        # Vocabulary.\n",
    "        chars = ''.join(self.cmds)\n",
    "        unique_chars = list(set(chars))\n",
    "        digits = ['{}'.format(i) for i in range(10)]\n",
    "        special = \"\\n\" + ' '\n",
    "        vocabulary = unique_chars + digits + list(special)\n",
    "        self.vocab = Indexing(vocabulary)\n",
    "        \n",
    "    def command(self):\n",
    "        cmd = random.choice(self.cmds)\n",
    "        if cmd == \"right\" or cmd == \"left\":\n",
    "            arg = 90\n",
    "        else: \n",
    "            arg = random.randint(0, 360)\n",
    "        return '{} {}'.format(cmd, arg)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.size\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        cmds = [self.command() for i in range(3)]\n",
    "        concat = '\\n'.join(cmds)\n",
    "        idxs = [self.vocab.direct(c) for c in concat]\n",
    "        return torch.tensor(idxs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Process\n",
    "\n",
    "\n",
    "![Learning](static/prediction.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Loss\n",
    "\n",
    "We'll use `nn.CrossEntropyLoss`, with a few customizations to be able to take our inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "class RNNCrossEntropyLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "    def forward(self, preds, truths):\n",
    "        T, B, H = preds.size()\n",
    "        Tt, Bt = truths.size()\n",
    "        assert( Bt == B and Tt == T)\n",
    "        \n",
    "        _preds = preds.view(-1, H)\n",
    "        _truths = truths.view(-1)\n",
    "\n",
    "        return self.criterion(_preds, _truths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Training subroutine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def train(model, optimizer, criterion, loader, train_method, epochs=100):\n",
    "    for epoch in tqdm(range(1, epochs+1), desc='epoch'):\n",
    "        iterator = enumerate(loader)\n",
    "        for i, x in tqdm(iterator, desc='train', leave=False):\n",
    "            x = x.transpose(1, 0)\n",
    "            export = train_method(model, optimizer, criterion, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def backpropogate_every(grad_interval):\n",
    "    def _inner(model, optimizer, criterion, x):\n",
    "        T, B = x.size()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        loss = 0\n",
    "        total_loss = 0\n",
    "        \n",
    "        h = model.h0(B)\n",
    "        for t in range(1, T):\n",
    "            src, tgt = x[t-1:t,:], x[t:t+1, :]\n",
    "            pred, h = model(src, h)\n",
    "            loss += criterion(pred, tgt)\n",
    "            if t % grad_interval == 0:\n",
    "                h_copy = h.detach()\n",
    "                loss.backward()\n",
    "                total_loss += loss.item()\n",
    "                loss = 0\n",
    "                optimizer.step()  \n",
    "                optimizer.zero_grad()\n",
    "                h = h_copy\n",
    "        avg_loss = total_loss/(T/grad_interval)\n",
    "        return {\"loss\": avg_loss}\n",
    "    return _inner\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Forward Pass\n",
    "\n",
    "```python\n",
    "# with seed as the current character, we try to learn the next character.\n",
    "src, tgt = x[t-1:t,:], x[t:t+1, :] \n",
    "\n",
    "# But we are aided by the hidden state which captures the context until now.\n",
    "pred, h = model(src, h) \n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Truncated BPTT\n",
    "\n",
    "This technique is called truncated backpropogation through time. Read more about it [here](https://r2rt.com/styles-of-truncated-backpropagation.html).\n",
    "\n",
    "\n",
    "```python\n",
    "loss += criterion(pred, tgt)\n",
    "if t % grad_interval == 0:\n",
    "    # we make a clone of context, without grad history.\n",
    "    h_copy = h.detach()     \n",
    "    loss.backward()              \n",
    "    total_loss += loss.item()\n",
    "    loss = 0\n",
    "    optimizer.step()  \n",
    "    optimizer.zero_grad()\n",
    "    h = h_copy\n",
    "    \n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Decoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Argmax Decoder\n",
    "\n",
    "Argmax decoding is heavily used in translation. \n",
    "\n",
    "The idea is to predict the most probable word, given the current context. \n",
    "\n",
    "We take a softmax over the output activations from Linear layer to convert them into probabilities.\n",
    "\n",
    "Then we take an argmax to find which would be the index which has maximum probability. \n",
    "\n",
    "The index corresponds to the word we need in `Indexing`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "class ArgmaxDecoder:\n",
    "    def __init__(self, vocab):\n",
    "        self.vocab = vocab\n",
    "    \n",
    "    def decode(self, activations):\n",
    "        probs = F.softmax(activations, dim=2)\n",
    "        mv, mi = probs.max(dim=2)\n",
    "        return self.vocab.inverse(mi.item()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Softmax with Temperature\n",
    "\n",
    "Argmax would give us the same predictions all the time, and enter a loop.\n",
    "\n",
    "But we want randomness in our predictions, and some control over the randomness.\n",
    "\n",
    "The solution: [Temperature](https://cs.stackexchange.com/questions/79241/what-is-temperature-in-lstm-and-neural-networks-generally)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "class TemperatureDecoder:\n",
    "    def __init__(self, vocab, temperature):\n",
    "        self.T = temperature\n",
    "        self.vocab = vocab\n",
    "    \n",
    "    def decode(self, activations):\n",
    "        feats_dist = activations.data.view(-1).div(self.T).exp()\n",
    "        top_i = torch.multinomial(feats_dist, 1)\n",
    "        return self.vocab.inverse(top_i.item())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Predicting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def predict(model, decoder, vocab, seed, max_length):\n",
    "    pred_str = seed\n",
    "    current = seed\n",
    "    h0 = model.h0(1)\n",
    "    \n",
    "    for i in range(max_length):\n",
    "        current = torch.Tensor([vocab.direct(current)]).long().view(1, 1)\n",
    "        activations, h0 = model(current, h0)\n",
    "        _next = decoder.decode(activations)\n",
    "        pred_str += _next   \n",
    "        current = _next\n",
    "        \n",
    "    return pred_str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Piecing it all together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "dataset = SimpleTurtleLogoDataset(200)\n",
    "loader = DataLoader(dataset)\n",
    "\n",
    "hidden_size = 64\n",
    "n_layers = 3\n",
    "\n",
    "input_size = len(dataset.vocab)\n",
    "output_size = input_size\n",
    "\n",
    "embedding = OneHotEmbedding(input_size)\n",
    "model = SequenceLearner(embedding, input_size, hidden_size, n_layers, output_size)\n",
    "optimizer = optim.Adam(model.parameters(),lr=1e-3)\n",
    "criterion = RNNCrossEntropyLoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "264cc2ea364c436eb937eb1bd54f6e37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='epoch', max=5, style=ProgressStyle(description_width='initial…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='train', max=1, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='train', max=1, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='train', max=1, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='train', max=1, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='train', max=1, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train(model, optimizer, criterion, loader, backpropogate_every(6), epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "argmaxdecoder = ArgmaxDecoder(dataset.vocab)\n",
    "t_decoder = TemperatureDecoder(dataset.vocab, 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "left 90\n",
      "backward 290\n",
      "left 90\n",
      "forward 99\n",
      "left 90\n",
      "backward 128\n",
      "left 90\n",
      "right 90\n",
      "right 90\n",
      "backward 166\n",
      "backward 116\n",
      "left 90\n",
      "forward 397\n",
      "left 90\n",
      "backward 378\n",
      "backward 398\n",
      "forward 116\n",
      "forward 108\n",
      "backward 22\n",
      "lef\n"
     ]
    }
   ],
   "source": [
    "pred_str = predict(model, t_decoder, dataset.vocab, 'l', 205)\n",
    "print(pred_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## `TextDataset`\n",
    "\n",
    "A class supposed to handle any large text with some limited length per line. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(self, path, tau):\n",
    "        content = open(path).read()\n",
    "        self.length = len(content)\n",
    "        self.tau = tau\n",
    "        \n",
    "        vocabulary = sorted(list(set(content)))\n",
    "        self.vocab = Indexing(vocabulary)\n",
    "        \n",
    "        self.lines = content.splitlines()\n",
    "        \n",
    "    def __getitem__(self, i):\n",
    "        start = self.tau*i\n",
    "        segment = self.lines[start:start+self.tau]\n",
    "        text = '\\n'.join(segment)\n",
    "        idxs = [self.vocab.v2idx[c] for c in text]\n",
    "        return torch.Tensor(idxs).long()\n",
    "        \n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.lines)//self.tau\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Tiny Shakespeare\n",
    "\n",
    "We'll use [Andrej Karpathy](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)'s Tiny Shakespeare dataset, and see if our network is able to learn major patterns over time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\r\n",
      "Before we proceed any further, hear me speak.\r\n",
      "\r\n",
      "All:\r\n",
      "Speak, speak.\r\n",
      "\r\n",
      "First Citizen:\r\n",
      "You are all resolved rather to die than to famish?\r\n",
      "\r\n",
      "All:\r\n",
      "Resolved. resolved.\r\n",
      "\r\n",
      "First Citizen:\r\n",
      "First, you know Caius Marcius is chief enemy to the people.\r\n",
      "\r\n",
      "All:\r\n",
      "We know't, we know't.\r\n",
      "\r\n",
      "First Citizen:\r\n",
      "Let us kill him, and we'll have corn at our own price.\r\n",
      "Is't a verdict?\r\n",
      "\r\n",
      "All:\r\n",
      "No more talking on't; let it be done: away, away!\r\n",
      "\r\n",
      "Second Citizen:\r\n",
      "One word, good citizens.\r\n",
      "\r\n",
      "First Citizen:\r\n"
     ]
    }
   ],
   "source": [
    "!head -n 29 data/input.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Let's test our model for larger, more diverse data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "dataset = TextDataset('data/input.txt', 5)\n",
    "loader = DataLoader(dataset)\n",
    "hidden_size = 64\n",
    "n_layers = 3\n",
    "\n",
    "input_size = len(dataset)\n",
    "output_size = input_size\n",
    "embedding_size = 10\n",
    "\n",
    "# embedding = OneHotEmbedding(len(dataset.vocab))\n",
    "embedding = nn.Embedding(input_size, embedding_size)\n",
    "model = SequenceLearner(embedding, embedding_size, hidden_size, n_layers, output_size)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "criterion = RNNCrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "with open(\"weights/shakespeare-e10.weights.checkpoint\", \"rb\") as in_file:\n",
    "    weights = torch.load(in_file)\n",
    "    model.load_state_dict(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ca1ad04f3df4c08b727b24901153499",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='epoch', max=10, style=ProgressStyle(description_width='initia…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='train', max=1, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='train', max=1, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='train', max=1, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='train', max=1, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='train', max=1, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='train', max=1, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fee847f58604f8f858c75c38a59f714",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=1, bar_style='info', description='train', max=1, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-9e7b701195a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbackpropogate_every\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-12-86f7d7b6db5d>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, criterion, loader, train_method, epochs)\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m             \u001b[0mexport\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-14-9f344376e0d1>\u001b[0m in \u001b[0;36m_inner\u001b[0;34m(model, optimizer, criterion, x)\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mgrad_interval\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                 \u001b[0mh_copy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m                 \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m                 \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/env3/lib/python3.5/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/env3/lib/python3.5/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train(model, optimizer, criterion, loader, backpropogate_every(40), epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Give his hand hath arms me compoungther of his son of the joyn to his blood a blood hath be that serve that shall breased our say the son poince from the son of the strike the brothard the hard of the brothing with his lorder hath the son of his son the grace him the death of the stand the banish the strike,\n",
      "And our learn the send some friend of heaven of the since the which the shall shall not and not be be his lords of his contres,\n",
      "And of the hand comforter of the peace of the world of his commind the world;\n",
      "The hand of their orong should and be friends our hand and this hand,\n",
      "The hold of his partition on the which loation our bed it is that my lords of more the father cannot some hold his father of his band of nothing do had the power the world the was holish he shall not the camour and with the wise he shall hath be is some fair charge call his grerate and could with his soul but back make of the king to against the canst and have so shall shall be be bear him commind the souls of t\n"
     ]
    }
   ],
   "source": [
    "argmaxdecoder = ArgmaxDecoder(dataset.vocab)\n",
    "t_decoder = TemperatureDecoder(dataset.vocab, 0.5)\n",
    "pred_str = predict(model, t_decoder, dataset.vocab, 'G', 1000)\n",
    "print(pred_str)\n",
    "\n",
    "with open(\"weights/shakespeare-e10.weights.checkpoint\", \"wb+\") as out_file:    \n",
    "    torch.save(model.state_dict(), out_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Exercises\n",
    "\n",
    "1. Try replacing temperature decoder with argmax decoder, and see what happens.\n",
    "2. In turtle logo and shakespeare, try using words instead of characters as a unit.\n",
    "3. I haven't plotted the losses over time, you're welcome to try and see what happens.\n",
    "4. The embedding layer's output, in Shakespeare case will be a dense representation of the character. Find the embeddings of all characters, and find their neighbourhood. You should see inferences like vowels occuring together.\n",
    "5. Adapt the model to use an LSTM or GRU instead of vanilla RNN. Are there improvements?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## What you can do further.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "### 1. Language model + Language model \n",
    "\n",
    "Learn two language models on two languages, **preferably using words as units.** \n",
    "\n",
    "Use the final hidden context from the first language model to start the time unrolling on the second language model.\n",
    "\n",
    "\n",
    "```python\n",
    "\n",
    "h = model.h0(B)                         # Initialized with 0, usually.\n",
    "h = first_language_model(src_sequence)  # dense representation of phrase is source language.\n",
    "idx = indexing.direct(\"<sos>\")          # Priming with <sos> token\n",
    "pred = embedding(idx)        \n",
    "for t in range(1, T):\n",
    "    tgt = x[t:t+1, :]\n",
    "    pred, h = model(pred, h)\n",
    "    loss += criterion(pred, tgt)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### 2. CNN feature extractor + Language model\n",
    "\n",
    "Use an output from something like ResNet or VGG-16, use it to initialize the hidden state of the RNN. \n",
    "\n",
    "Then time unroll to learn to predict captions.\n",
    "\n",
    "```python\n",
    "h = model.h0(B)                         # Initialized with 0, usually.\n",
    "h = vgg16(img)                          # Onward to image captioning.\n",
    "idx = indexing.direct(\"<sos>\")          # Priming with <sos> token\n",
    "pred = embedding(idx)        \n",
    "for t in range(1, T):\n",
    "    tgt = x[t:t+1, :]\n",
    "    pred, h = model(pred, h)\n",
    "    loss += criterion(pred, tgt)\n",
    "    ...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Thank you!"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
